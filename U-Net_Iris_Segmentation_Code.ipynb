{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c40c41ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images: 100%|██████████| 792/792 [02:53<00:00,  4.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Done — pure binary masks created (iris = white, pupil = black, background = black).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import onnxruntime as ort\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ---------------------------\n",
    "# Paths\n",
    "# ---------------------------\n",
    "MODEL_DIR = r\"C:\\Users\\awais\\OneDrive\\Desktop\\Thesis\\U-Net_Iris_Segmentation_Model\"\n",
    "MODEL_PATH = os.path.join(MODEL_DIR, \"iris_semseg_upp_scse_mobilenetv2.onnx\")\n",
    "INPUT_DIR = r\"C:\\Users\\awais\\OneDrive\\Desktop\\Thesis\\Iran\\IranIris\"\n",
    "OUTPUT_DIR = r\"C:\\Users\\awais\\OneDrive\\Desktop\\Iran_Iris_Segmented_Masks\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# ---------------------------\n",
    "# Model setup\n",
    "# ---------------------------\n",
    "ort_sess = ort.InferenceSession(MODEL_PATH, providers=[\"CPUExecutionProvider\"])\n",
    "\n",
    "# ---------------------------\n",
    "# Normalization parameters\n",
    "# ---------------------------\n",
    "MEAN = np.array([0.485, 0.456, 0.406])\n",
    "STD = np.array([0.229, 0.224, 0.225])\n",
    "\n",
    "# ---------------------------\n",
    "# Processing loop\n",
    "# ---------------------------\n",
    "for img_name in tqdm(os.listdir(INPUT_DIR), desc=\"Processing images\"):\n",
    "    img_path = os.path.join(INPUT_DIR, img_name)\n",
    "    img = cv2.imread(img_path)\n",
    "\n",
    "    if img is None:\n",
    "        print(f\"❌ Error reading {img_name}\")\n",
    "        continue\n",
    "\n",
    "    # Convert to RGB and resize to model input\n",
    "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img_resized = cv2.resize(img_rgb, (640, 480))\n",
    "\n",
    "    # Normalize: scale + z-score\n",
    "    img_norm = (img_resized / 255.0 - MEAN) / STD\n",
    "\n",
    "    # Add batch dimension and transpose to NCHW\n",
    "    img_input = np.transpose(img_norm, (2, 0, 1))[np.newaxis, :].astype(np.float32)\n",
    "\n",
    "    # Run inference\n",
    "    outputs = ort_sess.run(None, {\"input\": img_input})\n",
    "    preds = outputs[0][0]  # shape: (4, 480, 640)\n",
    "\n",
    "    # Threshold each class\n",
    "    iris_mask = (preds[1] > 0.5).astype(np.uint8)\n",
    "    pupil_mask = (preds[2] > 0.5).astype(np.uint8)\n",
    "\n",
    "    # Iris = white (255), pupil = black (0)\n",
    "    final_mask = ((iris_mask - pupil_mask) > 0).astype(np.uint8) * 255\n",
    "\n",
    "    # Resize mask to original image\n",
    "    final_mask_resized = cv2.resize(final_mask, (img.shape[1], img.shape[0]), interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "    # Save\n",
    "    save_path = os.path.join(OUTPUT_DIR, os.path.splitext(img_name)[0] + \".png\")\n",
    "    cv2.imwrite(save_path, final_mask_resized)\n",
    "\n",
    "print(\"✅ Done — pure binary masks created (iris = white, pupil = black, background = black).\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
